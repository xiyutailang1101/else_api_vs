<full-text-retrieval-response xmlns="http://www.elsevier.com/xml/svapi/article/dtd" xmlns:bk="http://www.elsevier.com/xml/bk/dtd" xmlns:cals="http://www.elsevier.com/xml/common/cals/dtd" xmlns:ce="http://www.elsevier.com/xml/common/dtd" xmlns:ja="http://www.elsevier.com/xml/ja/dtd" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:sa="http://www.elsevier.com/xml/common/struct-aff/dtd" xmlns:sb="http://www.elsevier.com/xml/common/struct-bib/dtd" xmlns:tb="http://www.elsevier.com/xml/common/table/dtd" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:prism="http://prismstandard.org/namespaces/basic/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><coredata><prism:url>https://api.elsevier.com/content/article/pii/S0034425725001798</prism:url><dc:identifier>doi:10.1016/j.rse.2025.114775</dc:identifier><eid>1-s2.0-S0034425725001798</eid><prism:doi>10.1016/j.rse.2025.114775</prism:doi><pii>S0034-4257(25)00179-8</pii><dc:title>A vision foundation model-based method for large-scale forest disturbance mapping using time series Sentinel-1 SAR data </dc:title><prism:publicationName>Remote Sensing of Environment</prism:publicationName><prism:aggregationType>Journal</prism:aggregationType><pubType>fla</pubType><prism:issn>00344257</prism:issn><prism:volume>325</prism:volume><prism:startingPage>114775</prism:startingPage><prism:pageRange>114775</prism:pageRange><articleNumber>114775</articleNumber><dc:format>text/xml</dc:format><prism:coverDate>2025-08-01</prism:coverDate><prism:coverDisplayDate>1 August 2025</prism:coverDisplayDate><prism:copyright>© 2025 Elsevier Inc. All rights are reserved, including those for text and data mining, AI training, and similar technologies.</prism:copyright><prism:publisher>Elsevier Inc. All rights are reserved, including those for text and data mining, AI training, and similar technologies.</prism:publisher><dc:creator>Tian, Yuping</dc:creator><dc:creator>Zhao, Feng</dc:creator><dc:creator>Meng, Ran</dc:creator><dc:creator>Sun, Rui</dc:creator><dc:creator>Zhang, Yuan</dc:creator><dc:creator>Shen, Yanyan</dc:creator><dc:creator>Wang, Bin</dc:creator><dc:creator>Liu, Jie</dc:creator><dc:creator>Li, Mingze</dc:creator><dc:description>
                  Accurate and timely forest disturbance mapping at large-scale is crucial for ecosystem protection and management. Sentinel-1 SAR data, with its all-weather capability and fine spatial-temporal resolutions, offers unique advantages for timely mapping of forest disturbance. Although deep learning models have been used for this purpose, they still struggle to fully exploit Sentinel-1 data's potential due to challenges in extracting multi-scale features and capturing context in complex landscape patterns. The advent of vision foundation models like the Segment Anything Model (SAM) offer new possibilities to improve large-scale forest disturbance mapping with Sentinel-1 data. However, trained with natural images, SAM had difficulty processing speckle noises in SAR and recognizing intricate forest disturbance patterns; additionally, challenges remained in developing model transfer strategies and improving model efficiency for large-scale applications. To address these issues, we propose SAMSR, a SAM-based framework adapted for forest disturbance mapping using time series Sentinel-1 data by adding CNN branches and cross-branch attention modules to enhance fine spatial details. Firstly, we evaluated SAMSR's performances against SAM, U-Net and DeepLabv3+ at four global disturbance hotspots with large variations in environmental conditions (Rondônia in Brazil, Guangxi in China, California in USA, and Hainan in China). Then, we test the model's transferability using fine-tuned transfer learning to identify the best transfer strategy and explore the potential of active learning to further enhance model efficiency. The results indicated that the SAMSR (IoU 0.50–0.78; F1 0.67–0.88) outperformed SAM, U-Net and DeepLabv3+ for about 23.08 %, 3.23 % and 1.59 % in IoU, respectively, while the multi-region model achieved optimal transfer performance (IoU 0.60–0.77; F1 0.75–0.87). Moreover, applying active learning can meet the saturation accuracy of traditional method with about 20 %–70 % less training samples, significantly reducing costs for fine-tuning the foundational model. This study thus provides a novel and efficient framework for large-scale forest disturbance monitoring at fine spatial-temporal resolutions, which could be critical for forest protection and ecological studies.
               </dc:description><openaccess>0</openaccess><openaccessArticle>false</openaccessArticle><openaccessType/><openArchiveArticle>false</openArchiveArticle><openaccessSponsorName/><openaccessSponsorType/><openaccessUserLicense/><dcterms:subject>Pan-tropical deforestation</dcterms:subject><dcterms:subject>Image segmentation</dcterms:subject><dcterms:subject>C-band SAR</dcterms:subject><dcterms:subject>Large-scale model transfer</dcterms:subject><dcterms:subject>Improved greedy sampling</dcterms:subject><link href="https://api.elsevier.com/content/article/pii/S0034425725001798" rel="self"/><link href="https://www.sciencedirect.com/science/article/pii/S0034425725001798" rel="scidir"/></coredata><scopus-id>105003557533</scopus-id><scopus-eid>2-s2.0-105003557533</scopus-eid><link href="https://api.elsevier.com/content/abstract/scopus_id/105003557533" rel="abstract"/><originalText><xocs:doc><xocs:meta><xocs:open-access xmlns:xocs="http://www.elsevier.com/xml/xocs/dtd"
                  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
                  xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd">
   <xocs:oa-article-status is-open-access="0" is-open-archive="0"/>
</xocs:open-access><xocs:available-online-date xmlns:xoe="http://www.elsevier.com/xml/xoe/dtd" yyyymmdd="20250429">2025-04-29</xocs:available-online-date></xocs:meta></xocs:doc></originalText></full-text-retrieval-response>